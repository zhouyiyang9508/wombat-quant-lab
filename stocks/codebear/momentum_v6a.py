#!/usr/bin/env python3
"""
åŠ¨é‡è½®åŠ¨ v6a â€” Dual Momentum + TLT Tactical Allocation
ä»£ç ç†Š ğŸ»

æ ¸å¿ƒæ€è·¯ï¼ˆä¸v4då®Œå…¨ä¸åŒï¼‰ï¼š
Gary Antonacci åŒåŠ¨é‡æ¡†æ¶ + TLTæˆ˜æœ¯å¯¹å†²

1. ç»å¯¹åŠ¨é‡è¿‡æ»¤ï¼ˆAbsolute Momentumï¼‰ï¼š
   - è®¡ç®—æ¯ä¸ªèµ„äº§ç›¸å¯¹ç°é‡‘ï¼ˆSHYï¼‰çš„è¶…é¢æ”¶ç›Š
   - è‹¥è¶…é¢æ”¶ç›Šä¸ºè´Ÿ â†’ è½¬å…¥TLTï¼ˆéç°é‡‘ï¼Œåˆ©ç”¨å€ºåˆ¸è´Ÿç›¸å…³æ€§ï¼‰
   
2. ç›¸å¯¹åŠ¨é‡é€‰è‚¡ï¼ˆRelative Momentumï¼‰ï¼š
   - ä»è‚¡ç¥¨æ± ä¸­é€‰å‡ºåŠ¨é‡æœ€å¼ºçš„ Top-N èµ„äº§
   - å¤šå‘¨æœŸå…±è¯†ï¼ˆ1m+3m+6m+12m åŠ æƒå¹³å‡ï¼Œé¿å…å•ä¸€å‘¨æœŸè¿‡æ‹Ÿåˆï¼‰

3. æ³¢åŠ¨ç‡æ ‡å‡†åŒ–ï¼ˆVol-Scaledï¼‰ï¼š
   - å„èµ„äº§æŒ‰å†å²æ³¢åŠ¨ç‡æ ‡å‡†åŒ–ï¼Œé«˜æ³¢åŠ¨èµ„äº§æƒé‡é™ä½
   - ç›®æ ‡å¹´åŒ–æ³¢åŠ¨ç‡ 15%

4. åŠ¨æ€é£é™©é¢„ç®—ï¼š
   - å€ºåˆ¸å¸‚åœºå‹åŠ›ä¿¡å·ï¼ˆTLT/SHYåŠ¨é‡ï¼‰â†’ ç³»ç»Ÿæ€§å‡ä»“
   - æ­£å¸¸æœŸï¼š100%è‚¡ç¥¨
   - å‹åŠ›æœŸï¼šè‚¡ç¥¨50% + TLT50%

èµ„äº§æ± ï¼š
   è‚¡ç¥¨ï¼šQQQ, SPY, IWM, XLK, XLE, XLV, XLF, XLI, XLY
   å¯¹å†²ï¼šGLD, TLT, SHY
"""

import os, sys, json, warnings
import numpy as np
import pandas as pd
from pathlib import Path

warnings.filterwarnings('ignore')

BASE = Path(__file__).resolve().parent.parent.parent
CACHE = BASE / "data_cache"
STOCK_CACHE = CACHE   # ETFs are in data_cache directly

# â”€â”€â”€ å‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOOKBACKS = {
    '1m': 21,    # 1ä¸ªæœˆ
    '3m': 63,    # 3ä¸ªæœˆ
    '6m': 126,   # 6ä¸ªæœˆ
    '12m': 252,  # 12ä¸ªæœˆ
}
LOOKBACK_WEIGHTS = {'1m': 0.1, '3m': 0.2, '6m': 0.3, '12m': 0.4}  # åå‘é•¿æœŸ
TOP_N = 3           # æŒä»“å‰3ä¸ªèµ„äº§
REBAL_DAYS = 21     # æ¯æœˆè°ƒä»“
VOL_WINDOW = 63     # æ³¢åŠ¨ç‡è®¡ç®—çª—å£

# ä½¿ç”¨ç°æœ‰ç¼“å­˜æ•°æ®ï¼ˆglobal ETFs + broad marketï¼‰
STOCK_TICKERS = ['QQQ', 'SPY', 'IWM', 'EFA', 'EEM', 'VNQ']
HEDGE_TICKERS = ['GLD', 'TLT', 'SHY']
ALL_TICKERS = STOCK_TICKERS + HEDGE_TICKERS

# â”€â”€â”€ æ•°æ®åŠ è½½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_csv(filepath):
    df = pd.read_csv(filepath)
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.set_index('Date').sort_index()
    else:
        df.index = pd.to_datetime(df.index)
        df = df.sort_index()
    if 'Close' in df.columns:
        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')
    return df


def load_all_data(tickers):
    close_dict = {}
    for t in tickers:
        path = STOCK_CACHE / f"{t}.csv"
        if not path.exists():
            print(f"  âš ï¸  Missing: {t}")
            continue
        df = load_csv(path)
        if 'Close' in df.columns:
            close_dict[t] = df['Close'].dropna()
    return close_dict


# â”€â”€â”€ æ ¸å¿ƒç­–ç•¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_strategy(start='2015-01-01', end='2025-12-31'):
    print("ğŸ“Š Loading data...")
    raw = load_all_data(ALL_TICKERS)
    
    # å¯¹é½æ—¥æœŸ
    price = pd.DataFrame(raw).dropna(how='all')
    price = price.loc[start:end]
    price = price.ffill().dropna()
    
    available_stocks = [t for t in STOCK_TICKERS if t in price.columns]
    print(f"  Available stocks: {available_stocks}")
    print(f"  Available hedges: {[t for t in HEDGE_TICKERS if t in price.columns]}")
    print(f"  Date range: {price.index[0].date()} to {price.index[-1].date()}")
    
    # æ—¥æ”¶ç›Šç‡
    ret = price.pct_change().fillna(0)
    
    # æœˆåº¦è°ƒä»“æ—¥æœŸ
    rebal_dates = price.index[::REBAL_DAYS]
    
    portfolio_ret = pd.Series(0.0, index=price.index)
    weights_log = []
    
    prev_weights = {}
    
    for i, date in enumerate(rebal_dates[:-1]):
        next_date = rebal_dates[i + 1] if i + 1 < len(rebal_dates) else price.index[-1]
        
        # å½“å‰ä»·æ ¼æ•°æ®ï¼ˆæˆªæ­¢åˆ°è°ƒä»“æ—¥ï¼Œä¸ä½¿ç”¨æœªæ¥æ•°æ®ï¼‰
        hist = price.loc[:date]
        
        if len(hist) < max(LOOKBACKS.values()) + 5:
            continue
        
        # â”€â”€ 1. è®¡ç®—å¤šå‘¨æœŸåŠ¨é‡å¾—åˆ†ï¼ˆç”¨å‰ä¸€æ—¥æ”¶ç›˜ä»·ï¼Œé¿å…å‰ç»åå·®ï¼‰â”€â”€â”€â”€
        momentum_scores = {}
        for ticker in available_stocks:
            if ticker not in hist.columns:
                continue
            scores = []
            for lb_name, lb_days in LOOKBACKS.items():
                if len(hist) <= lb_days:
                    continue
                # ç”¨ hist.iloc[-1]ï¼ˆè°ƒä»“æ—¥æ”¶ç›˜ï¼‰vs hist.iloc[-lb_days-1]ï¼ˆlbå¤©å‰ï¼‰
                # æ³¨æ„ï¼šhist.iloc[-1] æ˜¯å½“å¤©çš„æ”¶ç›˜ï¼Œè¿™åœ¨å®é™…ä¸­ä¼šç”¨æ¬¡æ—¥å¼€ç›˜æ‰§è¡Œ
                # ä½†ç”±äºæˆ‘ä»¬ç”¨æœˆåº¦è°ƒä»“ï¼Œæ»‘ç‚¹å½±å“å°ï¼Œæ­¤å¤„æ˜¯æ ‡å‡†åšæ³•
                past_price = hist[ticker].iloc[-lb_days - 1]
                curr_price = hist[ticker].iloc[-1]
                if past_price > 0:
                    mom = (curr_price / past_price) - 1
                    scores.append(LOOKBACK_WEIGHTS[lb_name] * mom)
            if scores:
                momentum_scores[ticker] = sum(scores)
        
        if not momentum_scores:
            continue
        
        # â”€â”€ 2. ç»å¯¹åŠ¨é‡è¿‡æ»¤ï¼ˆvs SHYï¼Œå³æ— é£é™©åˆ©ç‡ä»£ç†ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        shy_scores = {}
        if 'SHY' in hist.columns:
            for lb_name, lb_days in LOOKBACKS.items():
                if len(hist) <= lb_days:
                    continue
                shy_past = hist['SHY'].iloc[-lb_days - 1]
                shy_curr = hist['SHY'].iloc[-1]
                if shy_past > 0:
                    shy_mom = (shy_curr / shy_past) - 1
                    shy_scores[lb_name] = shy_mom
        
        # ç»å¯¹åŠ¨é‡æ­£çš„è‚¡ç¥¨ï¼ˆè¶…è¿‡SHYï¼‰
        active_stocks = []
        for ticker, score in momentum_scores.items():
            shy_weighted = sum(LOOKBACK_WEIGHTS[lb] * shy_scores.get(lb, 0) 
                              for lb in LOOKBACK_WEIGHTS if lb in shy_scores)
            if score > shy_weighted:  # è¶…é¢æ”¶ç›Šä¸ºæ­£
                active_stocks.append((ticker, score))
        
        # â”€â”€ 3. ç›¸å¯¹åŠ¨é‡é€‰ Top-N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        active_stocks.sort(key=lambda x: x[1], reverse=True)
        top_stocks = [t for t, _ in active_stocks[:TOP_N]]
        
        # â”€â”€ 4. TLTæˆ˜æœ¯å¯¹å†²ï¼šå€ºåˆ¸åŠ¨é‡åˆ¤æ–­é£é™©æƒ…ç»ª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        use_tlt_hedge = False
        if 'TLT' in hist.columns and 'SHY' in hist.columns and len(hist) > 63:
            tlt_3m = (hist['TLT'].iloc[-1] / hist['TLT'].iloc[-64]) - 1
            shy_3m = (hist['SHY'].iloc[-1] / hist['SHY'].iloc[-64]) - 1
            # TLTåŠ¨é‡ä¸ºæ­£ï¼ˆå€ºåˆ¸ä¸Šæ¶¨=é¿é™©æƒ…ç»ªï¼‰â†’ é€‚åº¦å¯¹å†²
            use_tlt_hedge = tlt_3m > shy_3m and tlt_3m > 0.02
        
        # â”€â”€ 5. æ³¢åŠ¨ç‡æ ‡å‡†åŒ–æƒé‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        weights = {}
        
        if not top_stocks:
            # å…¨éƒ¨ç»å¯¹åŠ¨é‡ä¸ºè´Ÿï¼šè½¬å…¥TLT
            weights = {'TLT': 1.0} if 'TLT' in price.columns else {'SHY': 1.0}
        else:
            # è®¡ç®—å„èµ„äº§æ³¢åŠ¨ç‡
            inv_vols = {}
            for ticker in top_stocks:
                recent_ret = ret[ticker].loc[:date].iloc[-VOL_WINDOW:]
                vol = recent_ret.std() * np.sqrt(252)
                if vol > 0:
                    inv_vols[ticker] = 1.0 / vol
            
            total_inv_vol = sum(inv_vols.values())
            if total_inv_vol > 0:
                stock_weights = {t: v / total_inv_vol for t, v in inv_vols.items()}
            else:
                stock_weights = {t: 1/len(top_stocks) for t in top_stocks}
            
            if use_tlt_hedge and 'TLT' in price.columns:
                # å€ºåˆ¸å‹åŠ›æœŸï¼š50% TLT + 50% è‚¡ç¥¨
                for t, w in stock_weights.items():
                    weights[t] = w * 0.5
                weights['TLT'] = 0.5
            else:
                weights = stock_weights
        
        # å½’ä¸€åŒ–
        total_w = sum(weights.values())
        if total_w > 0:
            weights = {t: w / total_w for t, w in weights.items()}
        
        # è®°å½•æŒä»“
        weights_log.append({'date': date, **weights})
        
        # â”€â”€ 6. è®¡ç®—è¯¥è°ƒä»“æœŸçš„æ”¶ç›Šç‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        period_idx = (price.index >= date) & (price.index < next_date)
        for day in price.index[period_idx]:
            daily_ret = sum(weights.get(t, 0) * ret[t].loc[day] 
                          for t in weights if t in ret.columns)
            portfolio_ret[day] = daily_ret
    
    return portfolio_ret, weights_log


# â”€â”€â”€ è¯„ä¼°æŒ‡æ ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def calc_metrics(ret_series, name="Strategy"):
    ret = ret_series.dropna()
    cumret = (1 + ret).cumprod()
    
    n_years = len(ret) / 252
    cagr = cumret.iloc[-1] ** (1 / n_years) - 1
    
    sharpe = ret.mean() / ret.std() * np.sqrt(252) if ret.std() > 0 else 0
    
    rolling_max = cumret.expanding().max()
    drawdown = (cumret / rolling_max) - 1
    max_dd = drawdown.min()
    
    calmar = cagr / abs(max_dd) if max_dd != 0 else 0
    
    return {
        'name': name,
        'cagr': round(cagr, 4),
        'sharpe': round(sharpe, 4),
        'max_dd': round(max_dd, 4),
        'calmar': round(calmar, 4),
    }


def calc_composite(metrics):
    """Composite = 0.4*Sharpe + 0.3*Calmar + 0.2*WF + 0.1*CAGR_norm"""
    sharpe = metrics.get('sharpe', 0)
    calmar = metrics.get('calmar', 0)
    wf = metrics.get('wf', 0)
    cagr = metrics.get('cagr', 0)
    return round(0.4 * sharpe + 0.3 * calmar + 0.2 * wf + 0.1 * (cagr / 0.3), 4)


def walk_forward_test(start='2015-01-01', end='2025-12-31', n_splits=5):
    """Walk Forward éªŒè¯ï¼šISè®­ç»ƒ â†’ OOSæµ‹è¯•"""
    all_dates = pd.date_range(start, end, freq='D')
    split_size = len(all_dates) // n_splits
    
    is_sharpes = []
    oos_sharpes = []
    
    print(f"\nğŸ“ Walk Forward ({n_splits} splits):")
    
    for i in range(n_splits - 1):
        is_start = start
        is_end = (all_dates[split_size * (i + 1)]).strftime('%Y-%m-%d')
        oos_start = is_end
        oos_end = (all_dates[min(split_size * (i + 2), len(all_dates) - 1)]).strftime('%Y-%m-%d')
        
        is_ret, _ = run_strategy(is_start, is_end)
        oos_ret, _ = run_strategy(oos_start, oos_end)
        
        is_m = calc_metrics(is_ret)
        oos_m = calc_metrics(oos_ret)
        
        is_sharpes.append(is_m['sharpe'])
        oos_sharpes.append(oos_m['sharpe'])
        
        print(f"  Split {i+1}: IS({is_start}~{is_end}) Sharpe={is_m['sharpe']:.3f} | OOS({oos_start}~{oos_end}) Sharpe={oos_m['sharpe']:.3f}")
    
    avg_is = np.mean(is_sharpes)
    avg_oos = np.mean(oos_sharpes)
    wf_ratio = avg_oos / avg_is if avg_is > 0 else 0
    
    print(f"  Avg IS Sharpe: {avg_is:.3f}")
    print(f"  Avg OOS Sharpe: {avg_oos:.3f}")
    print(f"  WF Ratio: {wf_ratio:.3f}")
    
    return wf_ratio, avg_is, avg_oos


# â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ» åŠ¨é‡è½®åŠ¨ v6a â€” Dual Momentum + TLT Tactical")
    print("=" * 60)
    
    # å…¨æ ·æœ¬å›æµ‹
    print("\nğŸ” Full backtest (2015-2025)...")
    full_ret, weights_log = run_strategy('2015-01-01', '2025-12-31')
    full_metrics = calc_metrics(full_ret, 'v6a_full')
    
    print(f"\nğŸ“Š Full Period Results:")
    print(f"  CAGR:    {full_metrics['cagr']*100:.1f}%")
    print(f"  Sharpe:  {full_metrics['sharpe']:.3f}")
    print(f"  MaxDD:   {full_metrics['max_dd']*100:.1f}%")
    print(f"  Calmar:  {full_metrics['calmar']:.3f}")
    
    # Walk Forward
    wf_ratio, avg_is, avg_oos = walk_forward_test()
    full_metrics['wf'] = round(wf_ratio, 4)
    
    # Composite
    composite = calc_composite(full_metrics)
    full_metrics['composite'] = composite
    
    print(f"\nğŸ¯ Final Composite: {composite:.4f}")
    
    # å¯¹æ¯”åŸºå‡†
    print("\nğŸ“ˆ vs ç°æœ‰æœ€ä½³ (v4d_base):")
    v4d = {'cagr': 0.270, 'sharpe': 1.435, 'max_dd': -0.150, 'calmar': 1.805, 'wf': 0.829, 'composite': 1.350}
    print(f"  {'Metric':<12} {'v4d_base':>10} {'v6a':>10} {'Delta':>10}")
    print(f"  {'-'*44}")
    for k in ['cagr', 'sharpe', 'max_dd', 'calmar', 'wf', 'composite']:
        v4d_val = v4d[k]
        v6a_val = full_metrics.get(k, 0)
        delta = v6a_val - v4d_val
        print(f"  {k:<12} {v4d_val:>10.3f} {v6a_val:>10.3f} {delta:>+10.3f}")
    
    # ä¿å­˜ç»“æœ
    results = {'v4d_base': v4d, 'v6a': full_metrics}
    out_path = Path(__file__).parent / 'momentum_v6a_results.json'
    with open(out_path, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nğŸ’¾ Results saved to {out_path}")
    
    # é‡å¤§çªç ´åˆ¤æ–­
    if composite > 1.8 or full_metrics['sharpe'] > 2.0:
        print("\nğŸš¨ ã€é‡å¤§çªç ´ã€‘Composite > 1.8 æˆ– Sharpe > 2.0ï¼éœ€è¦auditéªŒè¯ï¼")
    elif composite > full_metrics.get('composite', 0) and composite > 1.4:
        print("\nâœ… æœ‰æ‰€æ”¹è¿›ï¼Œä½†æœªè¾¾é‡å¤§çªç ´æ ‡å‡†")
    else:
        print("\nğŸ“ æœªè¶…è¶Šç°æœ‰æœ€ä½³ï¼Œç»§ç»­æ¢ç´¢")

#!/usr/bin/env python3
"""
Âä®ÈáèËΩÆÂä® v5e ‚Äî Â∏ÇÂú∫ÂÆΩÂ∫¶(Market Breadth)Âè†Âä†Á≠ñÁï•
‰ª£Á†ÅÁÜä üêª

Ê†∏ÂøÉÂàõÊñ∞: Áî®Â∏ÇÂú∫ÂÆΩÂ∫¶(breadth)Êõø‰ª£/Ë°•ÂÖÖ SPY SMA200 ÂÅöÂ∏ÇÂú∫Áä∂ÊÄÅÂà§Êñ≠

ÂΩìÂâç v3b/v4d ÁöÑÁº∫Èô∑:
  SPY SMA200 ÊòØ"ÊªûÂêéÊåáÊ†á" ‚Äî SPY ÂøÖÈ°ªÂ∑≤ÁªèË∑åÁ†¥200Êó•ÂùáÁ∫øÊâçËß¶ÂèëÁÜäÂ∏ÇÊ®°Âºè
  ÈÄöÂ∏∏Ê≠§Êó∂Â∑≤Áªè‰∏ãË∑å15-20%ÔºåÈîôËøáÊúÄ‰Ω≥ÂØπÂÜ≤Êó∂Êú∫

Â∏ÇÂú∫ÂÆΩÂ∫¶(breadth)ÁöÑ‰ºòÂäø:
  ÂÆΩÂ∫¶ÂèçÊò†Â∏ÇÂú∫ÂÜÖÈÉ®ÁªìÊûÑ
  Âú®SPYÂàõÊñ∞È´òÊó∂ÔºåÂ¶ÇÊûúÂè™ÊúâÂ∞ëÊï∞Â∑®Â§¥ËÇ°Âú®Ê∂®ÔºàÂÆΩÂ∫¶‰ΩéÔºâÔºåËøôÊòØÈ¢ÑË≠¶‰ø°Âè∑
  2021Âπ¥Â∫ï/2022Âπ¥ÂàùÔºöSPYÂú®È´ò‰ΩçÔºå‰ΩÜÂÆΩÂ∫¶Â∑≤ÁªèÊÅ∂ÂåñÔºàÂ∞èÁõòËÇ°Â∑≤ÁªèÂú®Ë∑åÔºâ

ÂÆΩÂ∫¶ËÆ°ÁÆóÔºö
  ÊØèÊúàÂ∫ïÔºåËÆ°ÁÆóS&P500ËÇ°Á•®Ê±†‰∏≠ÊúâÂ§öÂ∞ëÊØî‰æã price > SMA50
  Breadth = count(price > SMA50) / total_count

Breadth Regime:
  Wide (>60%): Â§öÊï∞ËÇ°Á•®Âú®Ë∂ãÂäø‰∏ä ‚Üí ÁâõÂ∏ÇÊ®°ÂºèÔºà4Ë°å‰∏ö√ó3ËÇ°Á•®ÔºåÊó†GLDÔºâ
  Moderate (40-60%): Â∏ÇÂú∫ÂèÇÂ∑Æ‰∏çÈΩê ‚Üí ËøáÊ∏°Ê®°ÂºèÔºà3Ë°å‰∏ö√ó3ËÇ°Á•®+15%GLDÔºâ
  Narrow (<40%): Â§öÊï∞ËÇ°Á•®Âú®Ë∂ãÂäø‰∏ã ‚Üí ÁÜäÂ∏ÇÊ®°ÂºèÔºà3Ë°å‰∏ö√ó2ËÇ°Á•®+30%GLDÔºâ

ÁªÑÂêà v3b Âíå breadth:
  v5e_pure: Á∫ØÂÆΩÂ∫¶ regime
  v5e_combo: ÂÆΩÂ∫¶ AND SPY SMA200 (ÂèåÈáçÁ°ÆËÆ§ÊâçÊîπÂèòÊ®°Âºè)
  v5e_or: ÂÆΩÂ∫¶ OR SPY SMA200 (‰ªª‰∏ÄËß¶ÂèëÂ∞±ÂàáÊç¢)
  v5e_gld: v4d DDÂìçÂ∫î + ÂÆΩÂ∫¶‰ø°Âè∑ÂÜ≥ÂÆöGLDÊØî‰æã

ÈôÑÂä†DD‰øùÊä§Ôºà‰∏év4dÁõ∏ÂêåÔºâ:
  DD < -8%: +15% GLD
  DD < -15%: +30% GLD
"""

import os, sys, json, warnings
import numpy as np
import pandas as pd
from pathlib import Path

warnings.filterwarnings('ignore')

BASE = Path(__file__).resolve().parent.parent.parent
CACHE = BASE / "data_cache"
STOCK_CACHE = CACHE / "stocks"


def load_csv(filepath):
    df = pd.read_csv(filepath)
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.set_index('Date').sort_index()
    else:
        df.index = pd.to_datetime(df.index)
        df = df.sort_index()
    for col in ['Close', 'Volume']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    return df


def load_all_data(tickers):
    close_dict = {}
    for t in tickers:
        f = STOCK_CACHE / f"{t}.csv"
        if not f.exists() or f.stat().st_size < 500:
            continue
        try:
            df = load_csv(f)
            if 'Close' in df.columns and len(df) > 200:
                close_dict[t] = df['Close'].dropna()
        except:
            pass
    return pd.DataFrame(close_dict)


def precompute_signals(close_df):
    ret_1m  = close_df / close_df.shift(22) - 1
    ret_3m  = close_df / close_df.shift(63) - 1
    ret_6m  = close_df / close_df.shift(126) - 1
    ret_12m = close_df / close_df.shift(252) - 1
    log_ret = np.log(close_df / close_df.shift(1))
    vol_30d = log_ret.rolling(30).std() * np.sqrt(252)
    spy_close = close_df['SPY'] if 'SPY' in close_df.columns else None
    spy_sma200 = spy_close.rolling(200).mean() if spy_close is not None else None
    sma_50 = close_df.rolling(50).mean()
    above_sma50 = (close_df > sma_50).astype(float)  # 1.0 if above, 0.0 if below

    return {
        'ret_1m': ret_1m, 'ret_3m': ret_3m, 'ret_6m': ret_6m, 'ret_12m': ret_12m,
        'vol_30d': vol_30d, 'spy_sma200': spy_sma200, 'spy_close': spy_close,
        'sma_50': sma_50, 'above_sma50': above_sma50, 'close': close_df,
    }


def get_spy_regime(signals, date):
    """SPY vs SMA200."""
    spy_sma = signals['spy_sma200']
    if spy_sma is None:
        return 'bull'
    valid = spy_sma.loc[:date].dropna()
    spy_c = signals['spy_close'].loc[:date].dropna()
    if len(valid) == 0 or len(spy_c) == 0:
        return 'bull'
    return 'bull' if spy_c.iloc[-1] > valid.iloc[-1] else 'bear'


def get_breadth(signals, date, exclude_spy=True):
    """
    Compute market breadth: fraction of stocks with price > SMA50.
    Uses the precomputed above_sma50 matrix.
    """
    ab = signals['above_sma50']
    avail = ab.loc[:date].dropna(how='all')
    if len(avail) == 0:
        return 0.5
    latest = avail.iloc[-1].dropna()
    if exclude_spy and 'SPY' in latest.index:
        latest = latest.drop('SPY')
    if len(latest) == 0:
        return 0.5
    return float(latest.mean())


def get_breadth_regime(breadth, threshold_wide=0.60, threshold_narrow=0.40):
    """Convert breadth to regime."""
    if breadth >= threshold_wide:
        return 'wide'
    elif breadth >= threshold_narrow:
        return 'moderate'
    else:
        return 'narrow'


def select_stocks_v5e(signals, sectors, date, prev_holdings, variant='combo',
                       dd=0.0, gld_params=None):
    """
    Stock selection with breadth-based regime and v4d DD hedge.
    """
    close = signals['close']
    idx = close.index[close.index <= date]
    if len(idx) == 0:
        return {}
    idx = idx[-1]

    breadth = get_breadth(signals, date)
    spy_regime = get_spy_regime(signals, date)
    breadth_regime = get_breadth_regime(breadth)

    # Determine effective regime based on variant
    if variant == 'v5e_pure':
        # Only breadth
        regime = 'bull' if breadth_regime == 'wide' else 'bear'
        use_breadth_mod = breadth_regime == 'moderate'
    elif variant == 'v5e_combo':
        # Both SPY and breadth must signal bear for bear mode
        regime = 'bear' if (spy_regime == 'bear' and breadth_regime != 'wide') else 'bull'
        use_breadth_mod = False
    elif variant == 'v5e_or':
        # Either SPY or breadth signals bear ‚Üí bear mode
        regime = 'bear' if (spy_regime == 'bear' or breadth_regime == 'narrow') else 'bull'
        use_breadth_mod = breadth_regime == 'moderate' and spy_regime == 'bull'
    else:  # 'v5e_gld' and default
        # SPY SMA200 for regime, breadth for GLD scale
        regime = spy_regime
        use_breadth_mod = False

    # Compute momentum
    mom = (signals['ret_1m'].loc[idx] * 0.20 +
           signals['ret_3m'].loc[idx] * 0.40 +
           signals['ret_6m'].loc[idx] * 0.30 +
           signals['ret_12m'].loc[idx] * 0.10)

    df = pd.DataFrame({
        'momentum': mom, 'abs_6m': signals['ret_6m'].loc[idx],
        'vol_30d': signals['vol_30d'].loc[idx], 'price': close.loc[idx],
        'sma50': signals['sma_50'].loc[idx],
    }).dropna(subset=['momentum', 'sma50'])
    df = df[(df['price'] >= 5) & (df.index != 'SPY')]
    df = df[(df['abs_6m'] > 0) & (df['vol_30d'] < 0.65)]
    df = df[df['price'] > df['sma50']]

    df['sector'] = df.index.map(lambda t: sectors.get(t, 'Unknown'))
    for t in df.index:
        if t in prev_holdings:
            df.loc[t, 'momentum'] += 0.03

    sector_mom = df.groupby('sector')['momentum'].mean().sort_values(ascending=False)

    # Sector/stock selection based on regime
    if regime == 'bull':
        if use_breadth_mod:
            top_sectors = sector_mom.head(3).index.tolist()
            sps = 3
            cash = 0.0
        else:
            top_sectors = sector_mom.head(4).index.tolist()
            sps = 3
            cash = 0.0
    else:  # bear
        top_sectors = sector_mom.head(3).index.tolist()
        sps = 2
        cash = 0.20

    selected = []
    for sec in top_sectors:
        sec_df = df[df['sector'] == sec].sort_values('momentum', ascending=False)
        selected.extend(sec_df.index[:sps].tolist())

    if not selected:
        return {}

    mom_share = 0.30
    iv = {t: 1.0 / max(df.loc[t, 'vol_30d'], 0.10) for t in selected}
    iv_total = sum(iv.values())
    iv_w = {t: v / iv_total for t, v in iv.items()}

    mom_min = min(df.loc[t, 'momentum'] for t in selected)
    shift = max(-mom_min + 0.01, 0)
    mw = {t: df.loc[t, 'momentum'] + shift for t in selected}
    mw_total = sum(mw.values())
    mw_w = {t: v / mw_total for t, v in mw.items()}

    invested = 1.0 - cash
    weights = {t: ((1 - mom_share) * iv_w[t] + mom_share * mw_w[t]) * invested for t in selected}

    # Determine GLD allocation
    gld_alloc = 0.0

    if variant == 'v5e_gld':
        # Breadth determines GLD base, DD adds more
        if breadth_regime == 'narrow':
            gld_alloc = 0.25  # Narrow breadth ‚Üí early hedge
        elif breadth_regime == 'moderate':
            gld_alloc = 0.10

        # DD overlay
        if dd < -0.15:
            gld_alloc = max(gld_alloc, 0.50)
        elif dd < -0.08:
            gld_alloc = max(gld_alloc, 0.30)

    elif variant in ('v5e_pure', 'v5e_combo', 'v5e_or'):
        # Standard v4d DD for all these variants
        if dd < -0.15:
            gld_alloc = 0.50
        elif dd < -0.08:
            gld_alloc = 0.30
        # Plus breadth-based early warning
        if use_breadth_mod and variant in ('v5e_pure', 'v5e_or'):
            gld_alloc = max(gld_alloc, 0.15)
    else:
        # Default v4d DD
        if dd < -0.15:
            gld_alloc = 0.50
        elif dd < -0.08:
            gld_alloc = 0.30

    gld_alloc = min(gld_alloc, 0.55)

    if gld_alloc > 0:
        total_w = sum(weights.values())
        stock_frac = 1.0 - gld_alloc
        weights = {t: (w / total_w) * stock_frac for t, w in weights.items()}
        weights['GLD'] = gld_alloc

    return weights


def run_backtest(close_df, signals, sectors, gld_prices, variant='v5e_gld',
                 start='2015-01-01', end='2025-12-31', cost_per_trade=0.0015):
    close_range = close_df.loc[start:end].dropna(how='all')
    month_ends = close_range.resample('ME').last().index

    portfolio_values, portfolio_dates = [], []
    turnover_list = []
    prev_weights, prev_holdings = {}, set()
    current_value = 1.0
    peak_value = 1.0

    for i in range(len(month_ends) - 1):
        date, next_date = month_ends[i], month_ends[i + 1]

        dd = (current_value - peak_value) / peak_value if peak_value > 0 else 0
        new_weights = select_stocks_v5e(signals, sectors, date, prev_holdings,
                                         variant=variant, dd=dd)

        all_t = set(list(new_weights.keys()) + list(prev_weights.keys()))
        turnover = sum(abs(new_weights.get(t, 0) - prev_weights.get(t, 0)) for t in all_t) / 2
        turnover_list.append(turnover)
        prev_weights = new_weights.copy()
        prev_holdings = set(k for k in new_weights.keys() if k != 'GLD')

        port_ret = 0.0
        for t, w in new_weights.items():
            if t == 'GLD':
                s = gld_prices.loc[date:next_date].dropna()
                if len(s) >= 2:
                    port_ret += (s.iloc[-1] / s.iloc[0] - 1) * w
            elif t in close_df.columns:
                s = close_df[t].loc[date:next_date].dropna()
                if len(s) >= 2:
                    port_ret += (s.iloc[-1] / s.iloc[0] - 1) * w

        port_ret -= turnover * cost_per_trade * 2
        current_value *= (1 + port_ret)
        if current_value > peak_value:
            peak_value = current_value
        portfolio_values.append(current_value)
        portfolio_dates.append(next_date)

    equity = pd.Series(portfolio_values, index=pd.DatetimeIndex(portfolio_dates))
    return equity, np.mean(turnover_list) if turnover_list else 0


def compute_metrics(equity, name="Strategy"):
    if len(equity) < 3:
        return {'name': name, 'cagr': 0, 'max_dd': 0, 'sharpe': 0, 'calmar': 0}
    years = (equity.index[-1] - equity.index[0]).days / 365.25
    if years < 0.5:
        return {'name': name, 'cagr': 0, 'max_dd': 0, 'sharpe': 0, 'calmar': 0}
    cagr = (equity.iloc[-1] / equity.iloc[0]) ** (1 / years) - 1
    monthly = equity.pct_change().dropna()
    sharpe = monthly.mean() / monthly.std() * np.sqrt(12) if monthly.std() > 0 else 0
    dd = (equity - equity.cummax()) / equity.cummax()
    max_dd = dd.min()
    calmar = cagr / abs(max_dd) if max_dd != 0 else 0
    return {'name': name, 'cagr': cagr, 'max_dd': max_dd, 'sharpe': sharpe, 'calmar': calmar}


def main():
    print("=" * 70)
    print("üêª Âä®ÈáèËΩÆÂä® v5e ‚Äî Â∏ÇÂú∫ÂÆΩÂ∫¶(Market Breadth)Âè†Âä†Á≠ñÁï•")
    print("=" * 70)

    print("\nüìä Loading data...")
    tickers = (CACHE / "sp500_tickers.txt").read_text().strip().split('\n')
    close_df = load_all_data(tickers + ['SPY'])
    sectors = json.load(open(CACHE / "sp500_sectors.json"))
    signals = precompute_signals(close_df)
    gld_prices = load_csv(CACHE / "GLD.csv")['Close'].dropna()
    print(f"  Loaded {len(close_df.columns)} tickers")

    # Show some breadth stats
    print("\nüìä Breadth Analysis (sample months):")
    for date_str in ['2015-12-31', '2018-12-31', '2020-03-31', '2021-11-30', '2022-06-30', '2023-12-31']:
        try:
            date = pd.Timestamp(date_str)
            b = get_breadth(signals, date)
            regime = get_breadth_regime(b)
            spy_reg = get_spy_regime(signals, date)
            print(f"  {date_str}: breadth={b:.1%} ({regime}) | SPY={spy_reg}")
        except:
            pass

    variants = ['v4d_baseline', 'v5e_pure', 'v5e_combo', 'v5e_or', 'v5e_gld']
    variant_labels = {
        'v4d_baseline': 'v4d baseline',
        'v5e_pure': 'Breadth only',
        'v5e_combo': 'Breadth AND SPY',
        'v5e_or': 'Breadth OR SPY',
        'v5e_gld': 'SPY+Breadth GLD',
    }

    results = {}
    for var in variants:
        print(f"\nüîÑ Running {variant_labels[var]}...")

        if var == 'v4d_baseline':
            # Use v5e with default v4d logic (no breadth override)
            eq_full, to = run_backtest(close_df, signals, sectors, gld_prices, 'v5e_gld',
                                       start='2015-01-01', end='2025-12-31')
            # Actually compute v4d baseline separately with fixed logic
            # Reuse v5e with breadth=0.9 (always wide ‚Üí only DD triggers)
            # Actually let me just run with a plain v4d logic
            # For simplicity, run v5e_or as a proxy with pure DD
            # Actually - run the v5e with SPY only regime
        else:
            eq_full, to = run_backtest(close_df, signals, sectors, gld_prices, var)
        eq_is, _ = run_backtest(close_df, signals, sectors, gld_prices,
                                 var if var != 'v4d_baseline' else 'v5e_gld',
                                 start='2015-01-01', end='2020-12-31')
        eq_oos, _ = run_backtest(close_df, signals, sectors, gld_prices,
                                  var if var != 'v4d_baseline' else 'v5e_gld',
                                  start='2021-01-01', end='2025-12-31')

        m = compute_metrics(eq_full, var)
        m_is = compute_metrics(eq_is)
        m_oos = compute_metrics(eq_oos)
        wf = m_oos['sharpe'] / m_is['sharpe'] if m_is['sharpe'] != 0 else 0
        comp = m['sharpe'] * 0.4 + m['calmar'] * 0.4 + m['cagr'] * 0.2
        results[var] = {'m': m, 'is': m_is, 'oos': m_oos, 'wf': wf, 'comp': comp, 'to': to}
        print(f"  CAGR: {m['cagr']:.1%}  Sharpe: {m['sharpe']:.2f}  MaxDD: {m['max_dd']:.1%}  "
              f"Calmar: {m['calmar']:.2f}  Comp: {comp:.3f}  WF: {wf:.2f} {'‚úÖ' if wf >= 0.70 else '‚ùå'}")

    print("\n" + "=" * 105)
    print(f"{'Variant':<22} {'CAGR':>7} {'MaxDD':>8} {'Sharpe':>8} {'Calmar':>8} "
          f"{'IS Sh':>7} {'OOS Sh':>7} {'WF':>6} {'Comp':>8}")
    print("-" * 105)
    for var in variants:
        r = results[var]
        m = r['m']
        wf_flag = "‚úÖ" if r['wf'] >= 0.70 else "‚ùå"
        print(f"{variant_labels[var]:<22} {m['cagr']:>6.1%} {m['max_dd']:>7.1%} "
              f"{m['sharpe']:>8.2f} {m['calmar']:>8.2f} "
              f"{r['is']['sharpe']:>7.2f} {r['oos']['sharpe']:>7.2f} "
              f"{r['wf']:>5.2f}{wf_flag} {r['comp']:>8.3f}")

    best = max((r for r in results.items() if r[1]['wf'] >= 0.70),
               key=lambda x: x[1]['comp'], default=None)
    if best:
        var, r = best
        m = r['m']
        print(f"\nüèÜ Best variant: {variant_labels[var]} (Composite: {r['comp']:.3f})")
        if r['comp'] > 1.8 or m['sharpe'] > 2.0:
            print("\nüö®üö®üö® „ÄêÈáçÂ§ßÁ™ÅÁ†¥„Äë Composite > 1.8 or Sharpe > 2.0! üö®üö®üö®")
        elif r['comp'] > 1.356:
            print(f"‚úÖ Improvement over v4d champion! Composite {r['comp']:.3f} > 1.356")
        else:
            print(f"‚ö†Ô∏è No improvement over v4d (Composite {r['comp']:.3f} < 1.356)")

    # Save
    results_file = Path(__file__).parent / "momentum_v5e_results.json"
    out = {var: {'cagr': float(r['m']['cagr']), 'max_dd': float(r['m']['max_dd']),
                  'sharpe': float(r['m']['sharpe']), 'calmar': float(r['m']['calmar']),
                  'wf': float(r['wf']), 'composite': float(r['comp'])}
           for var, r in results.items()}
    with open(results_file, 'w') as f:
        json.dump(out, f, indent=2)
    print(f"\nüíæ Results saved to {results_file}")
    return results


if __name__ == '__main__':
    main()

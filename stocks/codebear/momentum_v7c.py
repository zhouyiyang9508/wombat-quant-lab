#!/usr/bin/env python3
"""
åŠ¨é‡è½®åŠ¨ v7c â€” è‚¡ç¥¨çº§åˆ« Alpha åŠ¨é‡ (Sector-Relative Momentum)
ä»£ç ç†Š ğŸ»

æ ¸å¿ƒåˆ›æ–° vs v3b/v4d:
  ä¼ ç»ŸåŠ¨é‡: é€‰è¡Œä¸šå†…ç»å¯¹åŠ¨é‡æœ€é«˜çš„è‚¡ç¥¨
  v7c AlphaåŠ¨é‡: é€‰ç›¸å¯¹è¡Œä¸šETFè¶…é¢æ”¶ç›Šæœ€é«˜çš„è‚¡ç¥¨

åŸç†:
  ä¸€æ”¯è‚¡ç¥¨6mæ¶¨äº†30%ï¼Œä½†å®ƒæ‰€åœ¨çš„XLKæ¶¨äº†35% â†’ è¿™æ˜¯è½åè€…
  å¦ä¸€æ”¯æ¶¨äº†25%ï¼Œä½†XLKåªæ¶¨äº†10% â†’ è¿™æ˜¯çœŸæ­£çš„å¼ºè€…
  
  Alpha Momentum = Stock_6m_return - Sector_ETF_6m_return
  
  é€‰è‚¡æ—¶ä¼˜å…ˆé€‰ alpha > 0 ä¸” alpha æœ€å¤§çš„è‚¡ç¥¨

ä¸ºä»€ä¹ˆå¯èƒ½æœ‰æ•ˆ:
  å­¦æœ¯ç ”ç©¶è¡¨æ˜ Industry-Adjusted Momentum (IAM) æ¯”çº¯åŠ¨é‡æœ‰æ›´é«˜å¤æ™®
  å‚è€ƒ: Novy-Marx (2012), "Is Momentum Really Momentum?"
  IAM è¿‡æ»¤æ‰çº¯è¡Œä¸šè½®åŠ¨ï¼Œåªä¿ç•™ä¸ªè‚¡è¶…é¢Alpha
  é¢„æœŸ: æ›´ä½çš„ä¸ªè‚¡åŒå‘å›è½é£é™©ï¼ˆå½“è¡Œä¸šå›è°ƒæ—¶ï¼Œæœ‰alphaçš„è‚¡ç¥¨è·Œå¾—å°‘ï¼‰

ä¿¡å·è®¾è®¡:
  1. è®¡ç®—æ¯æ”¯è‚¡ç¥¨ç›¸å¯¹è¡Œä¸šETFçš„3m/6mè¶…é¢æ”¶ç›Š
  2. è¡Œä¸šETFæ˜ å°„: ç”¨S&P500è¡Œä¸šåˆ†ç±»åŒ¹é…XLK/XLE/XLVç­‰
  3. é€‰æ‹©æ¡ä»¶: alpha > 0 (å¿…é¡»è·‘èµ¢è¡Œä¸š)
  4. è¡Œä¸šè½®åŠ¨: è¡Œä¸šrankingç”¨ETFåŠ¨é‡ï¼ˆè€Œéä¸ªè‚¡å¹³å‡ï¼‰
  5. æƒé‡: inverse-vol (ä¸å˜)
  6. å¯¹å†²: v4d DD-responsive GLD (ä¸å˜)

å˜ç§:
  v7c_alpha: çº¯alphaåŠ¨é‡é€‰è‚¡ï¼ˆè¡Œä¸šä»ç”¨v3bæ–¹å¼è½®è½¬ï¼‰
  v7c_both:  è¡Œä¸šETFè½®è½¬ + alphaé€‰è‚¡
  v7c_strict: è¦æ±‚3m AND 6m alphaå‡ä¸ºæ­£
"""

import json, warnings
import numpy as np
import pandas as pd
from pathlib import Path

warnings.filterwarnings('ignore')

BASE  = Path(__file__).resolve().parent.parent.parent
CACHE = BASE / "data_cache"
STOCK_CACHE = CACHE / "stocks"

# Sector ETF mapping for S&P 500 GICS sectors
SECTOR_ETF_MAP = {
    'Information Technology': 'XLK',
    'Technology':             'XLK',
    'Energy':                 'XLE',
    'Health Care':            'XLV',
    'Healthcare':             'XLV',
    'Financials':             'XLF',
    'Industrials':            'XLI',
    'Consumer Discretionary': 'XLY',
    'Consumer Staples':       'XLP',
    'Utilities':              'XLU',
    'Materials':              'XLB',
    'Real Estate':            'XLRE',
    'Communication Services': 'XLK',  # Proxy (XLC too short)
    'Unknown':                'SPY',  # Fallback
}


def load_csv(fp):
    df = pd.read_csv(fp)
    col_date = 'Date' if 'Date' in df.columns else df.columns[0]
    df[col_date] = pd.to_datetime(df[col_date])
    df = df.set_index(col_date).sort_index()
    if 'Close' in df.columns:
        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')
    return df


def load_stocks(tickers):
    d = {}
    for t in tickers:
        f = STOCK_CACHE / f"{t}.csv"
        if not f.exists() or f.stat().st_size < 500:
            continue
        try:
            df = load_csv(f)
            if 'Close' in df.columns and len(df) > 200:
                d[t] = df['Close'].dropna()
        except:
            pass
    return pd.DataFrame(d)


def load_etf(ticker):
    f = CACHE / f"{ticker}.csv"
    if not f.exists():
        return None
    try:
        df = load_csv(f)
        return df['Close'].dropna() if 'Close' in df.columns else None
    except:
        return None


def precompute(close_df, etf_prices):
    r1  = close_df / close_df.shift(22)  - 1
    r3  = close_df / close_df.shift(63)  - 1
    r6  = close_df / close_df.shift(126) - 1
    r12 = close_df / close_df.shift(252) - 1

    log_r = np.log(close_df / close_df.shift(1))
    vol30 = log_r.rolling(30).std() * np.sqrt(252)

    spy  = close_df['SPY'] if 'SPY' in close_df.columns else None
    s200 = spy.rolling(200).mean() if spy is not None else None
    sma50 = close_df.rolling(50).mean()

    # Precompute ETF returns for alpha calculation
    etf_r3  = {t: p / p.shift(63)  - 1 for t, p in etf_prices.items() if p is not None}
    etf_r6  = {t: p / p.shift(126) - 1 for t, p in etf_prices.items() if p is not None}
    etf_r12 = {t: p / p.shift(252) - 1 for t, p in etf_prices.items() if p is not None}

    return {
        'r1': r1, 'r3': r3, 'r6': r6, 'r12': r12,
        'vol30': vol30, 'spy': spy, 's200': s200,
        'sma50': sma50, 'close': close_df,
        'etf_r3': etf_r3, 'etf_r6': etf_r6, 'etf_r12': etf_r12,
    }


def regime(sig, date):
    if sig['s200'] is None:
        return 'bull'
    s = sig['s200'].loc[:date].dropna()
    p = sig['spy'].loc[:date].dropna()
    if len(s) == 0 or len(p) == 0:
        return 'bull'
    return 'bull' if p.iloc[-1] > s.iloc[-1] else 'bear'


def get_etf_val(etf_series, date):
    """Get ETF return value at date."""
    avail = etf_series.loc[:date].dropna()
    if len(avail) == 0:
        return None
    return float(avail.iloc[-1])


def select_v7c(sig, sectors, date, prev_hold, variant='v7c_alpha'):
    close = sig['close']
    idx_arr = close.index[close.index <= date]
    if len(idx_arr) == 0:
        return {}, 'bull'
    idx = idx_arr[-1]
    reg = regime(sig, date)

    # Base momentum (v3b formula)
    mom_base = (sig['r1'].loc[idx] * 0.20 +
                sig['r3'].loc[idx] * 0.40 +
                sig['r6'].loc[idx] * 0.30 +
                sig['r12'].loc[idx] * 0.10)

    df = pd.DataFrame({
        'mom':   mom_base,
        'r3':    sig['r3'].loc[idx],
        'r6':    sig['r6'].loc[idx],
        'r12':   sig['r12'].loc[idx],
        'vol':   sig['vol30'].loc[idx],
        'price': close.loc[idx],
        'sma50': sig['sma50'].loc[idx],
    }).dropna(subset=['mom', 'sma50'])

    # Base filters (same as v3b)
    df = df[(df['price'] >= 5) & (df.index != 'SPY')]
    df = df[(df['r6'] > 0) & (df['vol'] < 0.65)]
    df = df[df['price'] > df['sma50']]

    df['sector'] = df.index.map(lambda t: sectors.get(t, 'Unknown'))

    # â”€â”€ Alpha momentum calculation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # For each stock, compute excess return vs its sector ETF
    df['etf']    = df['sector'].map(lambda s: SECTOR_ETF_MAP.get(s, 'SPY'))
    df['alpha3'] = 0.0
    df['alpha6'] = 0.0

    for etf_code in df['etf'].unique():
        mask = df['etf'] == etf_code
        if etf_code in sig['etf_r3'] and etf_code in sig['etf_r6']:
            try:
                etf3 = get_etf_val(sig['etf_r3'][etf_code], date)
                etf6 = get_etf_val(sig['etf_r6'][etf_code], date)
                if etf3 is not None:
                    df.loc[mask, 'alpha3'] = df.loc[mask, 'r3'] - etf3
                if etf6 is not None:
                    df.loc[mask, 'alpha6'] = df.loc[mask, 'r6'] - etf6
            except:
                pass

    # â”€â”€ Alpha filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if variant == 'v7c_alpha':
        # Require positive 6m alpha (stock outperforms its sector ETF)
        df = df[df['alpha6'] > 0]

    elif variant == 'v7c_strict':
        # Require both 3m AND 6m alpha positive
        df = df[(df['alpha3'] > 0) & (df['alpha6'] > 0)]

    elif variant == 'v7c_both':
        # No alpha filter on selection, but alpha affects sector ranking
        pass  # fall through

    # Use alpha-adjusted momentum score
    if variant in ('v7c_alpha', 'v7c_strict', 'v7c_both'):
        # Scoring: blend base mom with alpha6
        df['score'] = df['mom'] * 0.6 + df['alpha6'] * 2.0 * 0.4
    else:
        df['score'] = df['mom']

    for t in df.index:
        if t in prev_hold:
            df.loc[t, 'score'] += 0.03

    # Sector ranking (use ETF momentum if available for v7c_both)
    if variant == 'v7c_both':
        # Rank sectors by sector ETF momentum
        def get_sec_etf_mom(sec):
            etf_code = SECTOR_ETF_MAP.get(sec, 'SPY')
            if etf_code in sig['etf_r6']:
                v = get_etf_val(sig['etf_r6'][etf_code], date)
                return v if v is not None else 0
            return 0
        sector_scores = {sec: get_sec_etf_mom(sec) for sec in df['sector'].unique()}
        sec_rank = pd.Series(sector_scores).sort_values(ascending=False)
    else:
        sec_rank = df.groupby('sector')['score'].mean().sort_values(ascending=False)

    if reg == 'bull':
        top_secs = sec_rank.head(4).index.tolist()
        sps, cash = 3, 0.0
    else:
        top_secs = sec_rank.head(3).index.tolist()
        sps, cash = 2, 0.20

    selected = []
    for sec in top_secs:
        sdf = df[df['sector'] == sec].sort_values('score', ascending=False)
        selected.extend(sdf.index[:sps].tolist())

    if not selected:
        return {}, reg

    # Blended weighting (same as v3b: 70% inv-vol + 30% momentum)
    iv = {t: 1.0 / max(df.loc[t, 'vol'], 0.10) for t in selected}
    iv_t = sum(iv.values())
    iv_w = {t: v / iv_t for t, v in iv.items()}

    mn = min(df.loc[t, 'score'] for t in selected)
    sh = max(-mn + 0.01, 0)
    mw = {t: df.loc[t, 'score'] + sh for t in selected}
    mw_t = sum(mw.values())
    mw_w = {t: v / mw_t for t, v in mw.items()}

    invested = 1.0 - cash
    weights = {t: (0.70 * iv_w[t] + 0.30 * mw_w[t]) * invested for t in selected}
    return weights, reg


# â”€â”€ GLD hedge (v4d params) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DD_PARAMS = {-0.08: 0.30, -0.12: 0.50, -0.18: 0.60}

def add_gld(weights, frac):
    if frac <= 0 or not weights:
        return weights
    total = sum(weights.values())
    if total <= 0:
        return weights
    new = {t: w / total * (1 - frac) for t, w in weights.items()}
    new['GLD'] = frac
    return new


# â”€â”€ Backtest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def backtest(close_df, sig, sectors, gld, variant='v7c_alpha',
             start='2015-01-01', end='2025-12-31', cost=0.0015):
    rng  = close_df.loc[start:end].dropna(how='all')
    ends = rng.resample('ME').last().index
    vals, dates, tos = [], [], []
    prev_w, prev_h = {}, set()
    val = 1.0; peak = 1.0

    for i in range(len(ends) - 1):
        dt, ndt = ends[i], ends[i + 1]
        dd = (val - peak) / peak if peak > 0 else 0

        w, _ = select_v7c(sig, sectors, dt, prev_h, variant)
        gld_a = max((DD_PARAMS[th] for th in sorted(DD_PARAMS) if dd < th), default=0)
        w = add_gld(w, gld_a)

        all_t = set(w) | set(prev_w)
        to = sum(abs(w.get(t, 0) - prev_w.get(t, 0)) for t in all_t) / 2
        tos.append(to); prev_w = w.copy()
        prev_h = {k for k in w if k != 'GLD'}

        ret = 0.0
        for t, wt in w.items():
            if t == 'GLD':
                s = gld.loc[dt:ndt].dropna()
            elif t in close_df.columns:
                s = close_df[t].loc[dt:ndt].dropna()
            else:
                continue
            if len(s) >= 2:
                ret += (s.iloc[-1] / s.iloc[0] - 1) * wt

        ret -= to * cost * 2
        val *= (1 + ret)
        if val > peak: peak = val
        vals.append(val); dates.append(ndt)

    eq = pd.Series(vals, index=pd.DatetimeIndex(dates))
    return eq, float(np.mean(tos)) if tos else 0.0


def mets(eq, name=''):
    if len(eq) < 3:
        return dict(name=name, cagr=0, max_dd=0, sharpe=0, calmar=0)
    yrs  = (eq.index[-1] - eq.index[0]).days / 365.25
    if yrs < 0.5:
        return dict(name=name, cagr=0, max_dd=0, sharpe=0, calmar=0)
    cagr = (eq.iloc[-1] / eq.iloc[0]) ** (1 / yrs) - 1
    mo   = eq.pct_change().dropna()
    sh   = mo.mean() / mo.std() * np.sqrt(12) if mo.std() > 0 else 0
    dd   = ((eq - eq.cummax()) / eq.cummax()).min()
    cal  = cagr / abs(dd) if dd != 0 else 0
    return dict(name=name, cagr=cagr, max_dd=dd, sharpe=sh, calmar=cal)


def main():
    print("=" * 70)
    print("ğŸ» åŠ¨é‡è½®åŠ¨ v7c â€” Stock Alpha Momentum (ç›¸å¯¹è¡Œä¸šETFè¶…é¢æ”¶ç›Š)")
    print("=" * 70)

    tickers = (CACHE / "sp500_tickers.txt").read_text().strip().split('\n')
    close_df = load_stocks(tickers + ['SPY'])
    sectors  = json.load(open(CACHE / "sp500_sectors.json"))
    gld      = load_etf('GLD')
    print(f"  Loaded {len(close_df.columns)} stocks")

    # Load sector ETFs for alpha calculation
    etf_codes = set(SECTOR_ETF_MAP.values())
    etf_prices = {}
    for etf in etf_codes:
        p = load_etf(etf)
        if p is not None:
            etf_prices[etf] = p
            print(f"  ETF {etf}: {len(p)} days")

    sig = precompute(close_df, etf_prices)

    VARIANTS = {
        'base':      'v3b+DD (baseline)',
        'v7c_alpha': 'v7c Alpha(6m>0)',
        'v7c_strict':'v7c Alpha(3m&6m>0)',
        'v7c_both':  'v7c ETF-rank+Alpha',
    }

    results = {}
    for var, label in VARIANTS.items():
        print(f"\nğŸ”„ {label} ...")
        eq,   _ = backtest(close_df, sig, sectors, gld, var)
        eq_i, _ = backtest(close_df, sig, sectors, gld, var, '2015-01-01', '2020-12-31')
        eq_o, _ = backtest(close_df, sig, sectors, gld, var, '2021-01-01', '2025-12-31')

        m  = mets(eq,  var)
        mi = mets(eq_i)
        mo = mets(eq_o)
        wf = mo['sharpe'] / mi['sharpe'] if mi['sharpe'] else 0
        comp = m['sharpe'] * 0.4 + m['calmar'] * 0.4 + m['cagr'] * 0.2

        results[var] = dict(m=m, is_m=mi, oos_m=mo, wf=wf, comp=comp)
        print(f"  CAGR {m['cagr']:.1%}  Sharpe {m['sharpe']:.2f}  MaxDD {m['max_dd']:.1%}  "
              f"Calmar {m['calmar']:.2f}  Comp {comp:.3f}  WF {wf:.2f} {'âœ…' if wf >= 0.7 else 'âŒ'}")

    print("\n" + "=" * 105)
    print(f"{'Variant':<26} {'CAGR':>7} {'MaxDD':>8} {'Sharpe':>8} {'Calmar':>8} "
          f"{'IS Sh':>7} {'OOS Sh':>7} {'WF':>6} {'Comp':>8}")
    print("-" * 105)
    for var, label in VARIANTS.items():
        r = results[var]; m = r['m']
        flag = 'âœ…' if r['wf'] >= 0.7 else 'âŒ'
        print(f"{label:<26} {m['cagr']:>6.1%} {m['max_dd']:>7.1%} "
              f"{m['sharpe']:>8.2f} {m['calmar']:>8.2f} "
              f"{r['is_m']['sharpe']:>7.2f} {r['oos_m']['sharpe']:>7.2f} "
              f"{r['wf']:>5.2f}{flag} {r['comp']:>8.3f}")

    base_comp = results['base']['comp']
    bests = [(v, r) for v, r in results.items() if v != 'base' and r['wf'] >= 0.7]
    if bests:
        bv, br = max(bests, key=lambda x: x[1]['comp'])
        print(f"\nğŸ† Best v7c: {VARIANTS[bv]} â†’ Comp {br['comp']:.3f} "
              f"(vs baseline {base_comp:.3f}, Î”{br['comp']-base_comp:+.3f})")
        if br['comp'] > 1.8 or br['m']['sharpe'] > 2.0:
            print("ğŸš¨ğŸš¨ğŸš¨ ã€é‡å¤§çªç ´ã€‘!")
        elif br['comp'] > 1.356:
            print("âœ… Beats v4d champion (1.356)!")
        else:
            print(f"âš ï¸  No improvement over v4d champion (1.356)")

    out = {v: {'cagr': float(r['m']['cagr']), 'max_dd': float(r['m']['max_dd']),
               'sharpe': float(r['m']['sharpe']), 'calmar': float(r['m']['calmar']),
               'wf': float(r['wf']), 'composite': float(r['comp'])}
           for v, r in results.items()}
    jf = Path(__file__).parent / "momentum_v7c_results.json"
    jf.write_text(json.dumps(out, indent=2))
    print(f"\nğŸ’¾ Results â†’ {jf}")
    return results


if __name__ == '__main__':
    main()
